{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "79d74c76-1d53-4dd5-88d4-b0f3fda10cb5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df = spark.read.csv(\"/Volumes/workspace/default/oid_lab_4/mobile_app_interactions_expanded.csv\", header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bb0b4911-f040-482a-8f65-9d111966c5e0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0ba661bf-b0fd-4067-abe1-5f1e38a68467",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql import types as T\n",
    "\n",
    "# --- ВСТАНОВЛЕНО КОРЕКТНИЙ ФОРМАТ ---\n",
    "TIME_FORMAT = \"yyyy-MM-dd'T'HH:mm:ss\" \n",
    "# ------------------------------------\n",
    "\n",
    "# Припустімо, df - це ваш DataFrame\n",
    "\n",
    "# 1. Вибірка та перетворення типів\n",
    "df_cleaned = df.select(\n",
    "    F.col(\"user_id\").alias(\"user_id\"),\n",
    "    F.col(\"session_id\").alias(\"session_id\"),\n",
    "    # ВИПРАВЛЕНО: Використовуємо коректний TIME_FORMAT\n",
    "    F.try_to_timestamp(\n",
    "        F.col(\"timestamp\"), \n",
    "        F.lit(TIME_FORMAT)\n",
    "    ).alias(\"timestamp\") # Перейменуємо на \"timestamp\"\n",
    ")\n",
    "\n",
    "# 2. Очищення: відкидаємо рядки, де конвертація була невдалою\n",
    "df_cleaned = df_cleaned.filter(F.col(\"timestamp\").isNotNull())\n",
    "\n",
    "print(\"Схема робочого DataFrame після коректної конвертації:\")\n",
    "df_cleaned.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5d504518-c740-4f95-8a79-4abe054b0b7d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "display(df_cleaned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "575e7e09-c935-4bdf-ba3c-6f9abad7173b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.functions import min as F_min, max as F_max, avg as F_avg, count\n",
    "import time\n",
    "\n",
    "# --- Вхідний DataFrame: df_cleaned ---\n",
    "# Припустімо, що df_cleaned містить: \"user_id\", \"session_id\", \"timestamp\"\n",
    "df_input = df_cleaned \n",
    "\n",
    "\n",
    "# --- 1. Алгоритм 1: Налаштування за замовчуванням (Високе Перетасування) ---\n",
    "\n",
    "print(\"\\n--- Алгоритм 1: Налаштування за замовчуванням (T_A) ---\")\n",
    "# Spark викликає SHUFFLE за замовчуванням (зазвичай 200 розділів)\n",
    "\n",
    "start_time_A = time.time()\n",
    "\n",
    "# 1. Розрахунок тривалості сеансу: Групування за СПИСКОМ колонок\n",
    "df_sessions_A = df_input.groupBy(\"user_id\", \"session_id\").agg(\n",
    "    # Тривалість = MAX(\"timestamp\") - MIN(\"timestamp\")\n",
    "    (F_max(F.col(\"timestamp\")).cast(\"long\") - F_min(F.col(\"timestamp\")).cast(\"long\")).alias(\"session_duration_seconds\"),\n",
    "    count(\"*\").alias(\"event_count\")\n",
    ")\n",
    "\n",
    "# 2. Кінцева агрегація: Обчислення загального середнього значення (Action)\n",
    "avg_duration_A = df_sessions_A.agg(F_avg(F.col(\"session_duration_seconds\")).alias(\"average_session_duration\")).collect()\n",
    "\n",
    "T_A = time.time() - start_time_A\n",
    "\n",
    "print(f\"Час виконання Алгоритму 1 (T_A): {T_A:.2f} сек\")\n",
    "print(\"Середня тривалість сеансу (алгоритм 1):\", avg_duration_A[0][\"average_session_duration\"])\n",
    "\n",
    "# --- 2. Алгоритм 2: Оптимізоване Перетасування (Стратегія B) ---\n",
    "\n",
    "OPTIMAL_PARTITIONS = 24 \n",
    "\n",
    "print(f\"\\n--- Алгоритм 2: Оптимізоване Перетасування (T_B, {OPTIMAL_PARTITIONS} розділів) ---\")\n",
    "\n",
    "# ПЕРЕТАСУВАННЯ: Передаємо ОБИДВІ колонки до repartition\n",
    "df_low_shuffle = df_input.repartition(\n",
    "    OPTIMAL_PARTITIONS, \n",
    "    F.col(\"user_id\"), \n",
    "    F.col(\"session_id\")\n",
    ")\n",
    "\n",
    "start_time_B = time.time()\n",
    "\n",
    "# Групування та агрегація (ВИКОРИСТОВУЄМО \"timestamp\")\n",
    "# Групування також за двома колонками\n",
    "df_sessions_B = df_low_shuffle.groupBy(\"user_id\", \"session_id\").agg(\n",
    "    (F_max(F.col(\"timestamp\")).cast(\"long\") - F.min(F.col(\"timestamp\")).cast(\"long\")).alias(\"session_duration_seconds\"),\n",
    "    count(\"*\").alias(\"event_count\")\n",
    ")\n",
    "\n",
    "# Кінцева агрегація\n",
    "avg_duration_B = df_sessions_B.agg(F_avg(F.col(\"session_duration_seconds\")).alias(\"average_session_duration\")).collect()\n",
    "\n",
    "T_B = time.time() - start_time_B\n",
    "\n",
    "print(f\"Час виконання Алгоритму 2 (T_B): {T_B:.2f} сек\")\n",
    "print(\"Середня тривалість сеансу (алгоритм 2):\", avg_duration_B[0][\"average_session_duration\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5213331e-583d-4b38-87e5-93ccf872466a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "N = 8                # Кількість ядер\n",
    "# ----------------------------------------\n",
    "\n",
    "# 2. Оцінка Послідовної Частки (1-P)\n",
    "# Припускаємо, що T_seq (послідовний час) становить 10% від найкращого виміру (T_B)\n",
    "T_seq = 0.1 * T_B\n",
    "\n",
    "# T_par_on_N_cores = T_B - T_seq\n",
    "T_par_on_N_cores = T_B - T_seq\n",
    "\n",
    "# Оцінка загального часу паралельної роботи на одному ядрі (T_par)\n",
    "T_par_estimated = T_par_on_N_cores * N\n",
    "\n",
    "# 3. Обчислення частки паралелізму (P)\n",
    "# P = T_par / T_total_on_one_core\n",
    "T_1_estimated = T_seq + T_par_estimated # Час на одному ядрі (T_1)\n",
    "P = T_par_estimated / T_1_estimated \n",
    "P_seq = 1 - P\n",
    "\n",
    "print(\"--- Оцінка компонентів часу ---\")\n",
    "print(f\"Оцінений послідовний час (T_seq): {T_seq:.2f} сек\")\n",
    "print(f\"Оцінений загальний час на 1 ядрі (T_1): {T_1_estimated:.2f} сек\")\n",
    "print(f\"Оцінена частка паралельної роботи (P): {P:.4f} ({P*100:.2f}%)\")\n",
    "\n",
    "# --- 4. ЗАСТОСУВАННЯ ЗАКОНУ АМДАЛА ---\n",
    "\n",
    "# Розрахунок максимального теоретичного прискорення\n",
    "S_max_theoretical = 1 / (P_seq + (P / N))\n",
    "\n",
    "print(\"\\n--- Моделювання продуктивності ---\")\n",
    "print(f\"Максимальне теоретичне прискорення (S_max) на {N} ядрах: {S_max_theoretical:.2f} рази\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "12e44f6b-2394-43c4-909a-f50343188067",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "lab_4_oid",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
